#!/usr/bin/env python3
"""
–£–ª—É—á—à–µ–Ω–Ω—ã–π —Å–∫—Ä–∏–ø—Ç –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –∫–∞—á–µ—Å—Ç–≤–∞ —Å–æ–≤—Ä–µ–º–µ–Ω–Ω–æ–≥–æ –ø–µ—Ä–µ–≤–æ–¥–∞ –≤ JSON —Ñ–∞–π–ª–∞—Ö –º–æ–ª–∏—Ç–≤
–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –Ω–µ—Å–∫–æ–ª—å–∫–æ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π –∏ –æ–ø—Ä–µ–¥–µ–ª—è–µ—Ç, –¥–µ–π—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ –ª–∏ —ç—Ç–æ —Å–æ–≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ä—É—Å—Å–∫–∏–π —è–∑—ã–∫
"""

import json
import sys
import os
import re
from typing import Dict, Any, List, Tuple

def load_prayer_file(file_path: str) -> Dict[str, Any]:
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç JSON —Ñ–∞–π–ª –º–æ–ª–∏—Ç–≤—ã"""
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            return json.load(f)
    except Exception as e:
        print(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ —Ñ–∞–π–ª–∞ {file_path}: {e}")
        return None

def analyze_text_modernity(text: str) -> Tuple[bool, List[str]]:
    """
    –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Ç–µ–∫—Å—Ç –Ω–∞ —Å–æ–≤—Ä–µ–º–µ–Ω–Ω–æ—Å—Ç—å —Ä—É—Å—Å–∫–æ–≥–æ —è–∑—ã–∫–∞
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç (is_modern, issues_list)
    """
    issues = []
    
    # –†–∞–∑–±–∏–≤–∞–µ–º —Ç–µ–∫—Å—Ç –Ω–∞ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è (–ø—Ä–∏–º–µ—Ä–Ω–æ)
    sentences = re.split(r'[.!?]+', text)
    sentences = [s.strip() for s in sentences if s.strip()]
    
    # –ë–µ—Ä–µ–º –ø–µ—Ä–≤—ã–µ 5 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
    sample_sentences = sentences[:5]
    
    if not sample_sentences:
        return False, ["–¢–µ–∫—Å—Ç –ø—É—Å—Ç–æ–π –∏–ª–∏ –Ω–µ —Å–æ–¥–µ—Ä–∂–∏—Ç –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π"]
    
    print(f"üìù –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –ø–µ—Ä–≤—ã–µ {len(sample_sentences)} –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π:")
    for i, sentence in enumerate(sample_sentences, 1):
        print(f"  {i}. {sentence[:100]}{'...' if len(sentence) > 100 else ''}")
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º —Å–ª–æ–≤–∞—Ä—å –∞—Ä—Ö–∞–∏–∑–º–æ–≤ –∏–∑ —Ñ–∞–π–ª–∞
    archaisms_file = "extracted_words/archaisms.txt"
    archaic_words = set()
    
    try:
        with open(archaisms_file, 'r', encoding='utf-8') as f:
            for line in f:
                word = line.strip()
                if word and not word.startswith('#'):
                    archaic_words.add(word)
    except FileNotFoundError:
        print(f"–§–∞–π–ª {archaisms_file} –Ω–µ –Ω–∞–π–¥–µ–Ω, –∏—Å–ø–æ–ª—å–∑—É–µ–º –±–∞–∑–æ–≤—ã–π —Å–ª–æ–≤–∞—Ä—å")
        archaic_words = {
            '—è–∫–æ', '–µ–∂–µ', '–∏–∂–µ', '—è–∂–µ', '–µ–≥–æ–∂–µ', '–ø–∞—á–µ', '–Ω–µ–∂–µ–ª–∏',
            '–≤–æ', '–∫–æ', '–º–æ–ª–∏—à–∏', '–¥–∞—Ä—É–µ—à–∏', '—Å–ø–æ–¥–æ–±–∏', '–∏–∑–±–∞–≤–∏',
            '–∞—Ä—Ö–∏—Å—Ç—Ä–∞—Ç–∏–∂–µ', '–∞—Ä—Ö–∞–Ω–≥–µ–ª–µ', '—Å–≤—è—Ç—ã–π', '–±–ª–∞–≥–æ—É—Ç—Ä–æ–±–∏–µ',
            '–Ω–∞–ø—Ä–∞—Å–Ω–∏–µ', '–≤—Å—è–∫–∞–≥–æ', '–±–ª–∞–≥–∞–≥–æ', '–∞—â–µ', '–∞–∑', '–µ—Å–∏',
            '–º—è', '—Ç–≤–æ–µ–≥–æ', '—Ç–≤–æ–µ', '—Ç–≤–æ—è', '—Ç–≤–æ–∏—Ö', '—Ç–≤–æ–∏–º', '—Ç–≤–æ—é',
            '—Ç–≤–æ–∏', '—Ç–≤–æ–µ–º—É', '—Ç–≤–æ–µ—è', '—Ç–≤–æ–π', '—Ç–≤–æ–µ–π', '—Ç–≤–æ–µ—é'
        }
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞ —Ü–µ—Ä–∫–æ–≤–Ω–æ—Å–ª–∞–≤—è–Ω—Å–∫–∏–µ —Ñ–æ—Ä–º—ã –ø–æ –ø–∞—Ç—Ç–µ—Ä–Ω–∞–º
    church_slavonic_patterns = [
        # –ê—Ä—Ö–∞–∏—á–Ω—ã–µ –æ–∫–æ–Ω—á–∞–Ω–∏—è
        r'\b\w+–∏–µ\b',  # –Ω–∞–ø—Ä–∞—Å–Ω–∏–µ, –±–ª–∞–≥–æ—É—Ç—Ä–æ–±–∏–µ
        r'\b\w+–∞–≥–æ\b',  # –±–ª–∞–≥–∞–≥–æ
        r'\b\w+—è–≥–æ\b',  # –≤—Å—è–∫–∞–≥–æ
        r'\b\w+—à–∏\b',  # –º–æ–ª–∏—à–∏, –¥–∞—Ä—É–µ—à–∏
        r'\b\w+—à–∏—Å—è\b',  # –º–æ–ª–∏—à–∏—Å—è
        r'\b\w+—à–∏–∏\b',  # –º–æ–ª—è—â–∏–∏
    ]
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–∞–∂–¥–æ–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ –Ω–∞ –∞—Ä—Ö–∞–∏—á–Ω—ã–µ —Å–ª–æ–≤–∞
    archaic_count = 0
    modern_count = 0
    
    for sentence in sample_sentences:
        words = re.findall(r'\b\w+\b', sentence.lower())
        
        for word in words:
            if word in archaic_words:
                archaic_count += 1
                issues.append(f"–ê—Ä—Ö–∞–∏—á–Ω–æ–µ —Å–ª–æ–≤–æ '{word}' –≤ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–∏: {sentence[:50]}...")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞ —Å–æ–≤—Ä–µ–º–µ–Ω–Ω—ã–µ –∫–æ–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏
        modern_patterns = [
            r'\b–∫–∞–∫\b',  # –∫–∞–∫ (–≤–º–µ—Å—Ç–æ —è–∫–æ)
            r'\b—á—Ç–æ\b',  # —á—Ç–æ (–≤–º–µ—Å—Ç–æ –µ–∂–µ)
            r'\b–∫–æ—Ç–æ—Ä—ã–π\b',  # –∫–æ—Ç–æ—Ä—ã–π (–≤–º–µ—Å—Ç–æ –∏–∂–µ)
            r'\b–∫–æ—Ç–æ—Ä–∞—è\b',  # –∫–æ—Ç–æ—Ä–∞—è (–≤–º–µ—Å—Ç–æ —è–∂–µ)
            r'\b–≤\b',  # –≤ (–≤–º–µ—Å—Ç–æ –≤–æ)
            r'\b–∫\b',  # –∫ (–≤–º–µ—Å—Ç–æ –∫–æ)
            r'\b–±–æ–ª–µ–µ\b',  # –±–æ–ª–µ–µ (–≤–º–µ—Å—Ç–æ –ø–∞—á–µ)
            r'\b—á–µ–º\b',  # —á–µ–º (–≤–º–µ—Å—Ç–æ –Ω–µ–∂–µ–ª–∏)
        ]
        
        for pattern in modern_patterns:
            if re.search(pattern, sentence, re.IGNORECASE):
                modern_count += 1
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–æ –ø–∞—Ç—Ç–µ—Ä–Ω–∞–º (–¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ)
    for sentence in sample_sentences:
        for pattern in church_slavonic_patterns:
            matches = re.findall(pattern, sentence, re.IGNORECASE)
            if matches:
                for match in matches:
                    if len(match) > 3:  # –ò–≥–Ω–æ—Ä–∏—Ä—É–µ–º –∫–æ—Ä–æ—Ç–∫–∏–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è
                        archaic_count += 1
                        issues.append(f"–ê—Ä—Ö–∞–∏—á–Ω–∞—è —Ñ–æ—Ä–º–∞ '{match}' –≤ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–∏: {sentence[:50]}...")
    
    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º, —Å–æ–≤—Ä–µ–º–µ–Ω–Ω—ã–π –ª–∏ —Ç–µ–∫—Å—Ç
    # –ï—Å–ª–∏ –º–∞–ª–æ –∞—Ä—Ö–∞–∏—á–Ω—ã—Ö —Å–ª–æ–≤ - —Ç–µ–∫—Å—Ç —Å–æ–≤—Ä–µ–º–µ–Ω–Ω—ã–π
    is_modern = archaic_count < 2
    
    return is_modern, issues

def analyze_prayer_file(file_path: str) -> Dict[str, Any]:
    """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Ñ–∞–π–ª –º–æ–ª–∏—Ç–≤—ã –Ω–∞ –∫–∞—á–µ—Å—Ç–≤–æ —Å–æ–≤—Ä–µ–º–µ–Ω–Ω–æ–≥–æ –ø–µ—Ä–µ–≤–æ–¥–∞"""
    print(f"\nüîç –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Ñ–∞–π–ª: {file_path}")
    
    data = load_prayer_file(file_path)
    if not data:
        return {"error": "–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å —Ñ–∞–π–ª"}
    
    result = {
        "file": file_path,
        "title": data.get("title", "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ"),
        "contentModern_exists": "contentModern" in data,
        "contentModern_length": 0,
        "is_modern": False,
        "issues": [],
        "sample_text": ""
    }
    
    if "contentModern" in data:
        content_modern = data["contentModern"]
        result["contentModern_length"] = len(content_modern)
        result["sample_text"] = content_modern[:300] + "..." if len(content_modern) > 300 else content_modern
        
        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –∫–∞—á–µ—Å—Ç–≤–æ –ø–µ—Ä–µ–≤–æ–¥–∞
        is_modern, issues = analyze_text_modernity(content_modern)
        result["is_modern"] = is_modern
        result["issues"] = issues
        
        print(f"üìÑ –ó–∞–≥–æ–ª–æ–≤–æ–∫: {result['title']}")
        print(f"üìä –î–ª–∏–Ω–∞ contentModern: {result['contentModern_length']} —Å–∏–º–≤–æ–ª–æ–≤")
        print(f"‚úÖ –°–æ–≤—Ä–µ–º–µ–Ω–Ω—ã–π –ø–µ—Ä–µ–≤–æ–¥: {'–î–ê' if is_modern else '–ù–ï–¢'}")
        
        if issues:
            print("‚ö†Ô∏è  –ü—Ä–æ–±–ª–µ–º—ã:")
            for issue in issues[:5]:  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Ç–æ–ª—å–∫–æ –ø–µ—Ä–≤—ã–µ 5 –ø—Ä–æ–±–ª–µ–º
                print(f"   - {issue}")
        else:
            print("‚ú® –ü—Ä–æ–±–ª–µ–º –Ω–µ –Ω–∞–π–¥–µ–Ω–æ")
    else:
        print("‚ùå –ü–æ–ª–µ contentModern –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç")
    
    return result

def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    if len(sys.argv) < 2:
        print("–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ: python analyze_modernity.py <–ø—É—Ç—å_–∫_—Ñ–∞–π–ª—É>")
        print("–ü—Ä–∏–º–µ—Ä: python analyze_modernity.py data/prayers/molitva-5-pyatnitsa-arhangelu-selafiilu.json")
        return
    
    file_path = sys.argv[1]
    
    if not os.path.exists(file_path):
        print(f"–§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {file_path}")
        return
    
    result = analyze_prayer_file(file_path)
    
    # –í—ã–≤–æ–¥–∏–º –∏—Ç–æ–≥–æ–≤—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç
    print(f"\nüìã –ò–¢–û–ì–û–í–´–ô –†–ï–ó–£–õ–¨–¢–ê–¢:")
    print(f"   –§–∞–π–ª: {result['file']}")
    print(f"   –°–æ–≤—Ä–µ–º–µ–Ω–Ω—ã–π –ø–µ—Ä–µ–≤–æ–¥: {'‚úÖ –î–ê' if result['is_modern'] else '‚ùå –ù–ï–¢'}")
    if result['issues']:
        print(f"   –ù–∞–π–¥–µ–Ω–æ –ø—Ä–æ–±–ª–µ–º: {len(result['issues'])}")

if __name__ == "__main__":
    main()
